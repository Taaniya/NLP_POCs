{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Explore_Language_Agnostic_BERT_Sentence_Embedding",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v67mqdruGixP",
        "colab_type": "text"
      },
      "source": [
        "This notebook explores capabilities of recent State-of-the-art Multilingual model - Language agnostic BERT Sentence Embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5poh8miy7Zbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "f01253b7-69e5-4ae4-ba62-4ccaace691d5"
      },
      "source": [
        "! pip install bert-for-tf2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/c1/015648a2186b25c6de79d15bec40d3d946fcf1dd5067d1c1b28009506486/bert-for-tf2-0.14.6.tar.gz (40kB)\n",
            "\r\u001b[K     |████████                        | 10kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 1.8MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.6-cp36-none-any.whl size=30318 sha256=bf0df6eb7298fd2045ebd366e262b787af257ee87f9caff2477abd5cb6584780\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/a0/b4/75b0601ebaa41e517a797fe9cea119c789664c8408f8a74ae9\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7304 sha256=b54ca9a8b16a2ea43751108f950671d93acefc76b7a007d3e042ff19f4093aa1\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19475 sha256=0c84a5d778fed49dcb40b9be07972821e4641c24152da65533848712b52adf41\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.6 params-flow-0.8.2 py-params-0.9.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDC7FJRHR6tZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import bert"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY1doigcRw1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c0bcd05-96a0-4a68-f255-5f5f7a0b8578"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoW8mHUFS7GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABSE_model_URL = \"https://tfhub.dev/google/LaBSE/1\"\n",
        "MAX_SEQ_LENGTH = 64"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_biH25-R4pT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getModel(model_url, max_seq_length):\n",
        "  # Load the saved LaBSE model as Keras layer. \n",
        "  # Set trainable to True to enable weight update for fine-tuning the model for down stream task\n",
        "  labse_layer = hub.KerasLayer(handle=model_url, trainable=True, name='labse')\n",
        "\n",
        "  # Define Inputs\n",
        "  input_word_ids = tf.keras.Input(shape=(max_seq_length, ), dtype=tf.int32, name='input_word_ids')\n",
        "  input_mask = tf.keras.Input(shape=(max_seq_length, ), dtype=tf.int32, name='input_mask')\n",
        "  input_segment_ids = tf.keras.Input(shape=(max_seq_length, ), dtype=tf.int32, name='input_segment_ids')\n",
        "\n",
        "  # LABSE layer - what is pooled output\n",
        "  pooled_output, _ = labse_layer([input_word_ids, input_mask ,input_segment_ids])\n",
        "  \n",
        "  # The output is L2 normalized - why L2 normalization in the layer\n",
        "  pooled_output = tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1), name='l2_normalized_pooling')(pooled_output)\n",
        "\n",
        "  # Define Model\n",
        "  return tf.keras.Model(inputs=[input_word_ids, input_mask ,input_segment_ids], outputs=pooled_output), labse_layer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w43FATmug9Mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labse_model, labse_layer = getModel(LABSE_model_URL, MAX_SEQ_LENGTH)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mwGV7ljhGWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "2a31dfab-a093-4449-c658-dc55ed223173"
      },
      "source": [
        "labse_model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_segment_ids (InputLayer)  [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "labse (KerasLayer)              [(None, 768), (None, 470926849   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 input_segment_ids[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "l2_normalized_pooling (Lambda)  (None, 768)          0           labse[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 470,926,849\n",
            "Trainable params: 470,926,848\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIbzyuls75N_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_file = labse_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = labse_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = bert.bert_tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mjcO5G08ItF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fef4613b-43b2-4ee1-e00f-17658fa2e4b9"
      },
      "source": [
        "tokenizer.tokenize(\"Thanks, I like this application\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thanks', ',', 'I', 'like', 'this', 'application']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2LRSjAf81qR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1269a723-8bd6-4315-9e43-08b9dc718780"
      },
      "source": [
        "tokenizer.tokenize(\"धन्यवाद, मुझे यह एप्लीकेशन पसंद है\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['धन्यवाद', ',', 'मुझे', 'यह', 'एप', '##्ली', '##के', '##शन', 'पसंद', 'है']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WOXPNeR88yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_input(input_strings, tokenizer, max_seq_length):\n",
        "\n",
        "  input_ids_all, input_mask_all, segment_ids_all = [], [], []\n",
        "  for input_string in input_strings:\n",
        "    # Tokenize input.\n",
        "    input_tokens = [\"[CLS]\"] + tokenizer.tokenize(input_string) + [\"[SEP]\"]\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n",
        "    sequence_length = min(len(input_ids), max_seq_length)\n",
        "\n",
        "    # Padding or truncation.\n",
        "    if len(input_ids) >= max_seq_length:\n",
        "      input_ids = input_ids[:max_seq_length]\n",
        "    else:\n",
        "      input_ids = input_ids + [0] * (max_seq_length - len(input_ids))\n",
        "\n",
        "    input_mask = [1] * sequence_length + [0] * (max_seq_length - sequence_length)\n",
        "\n",
        "    input_ids_all.append(input_ids)\n",
        "    input_mask_all.append(input_mask)\n",
        "    segment_ids_all.append([0] * max_seq_length)\n",
        "\n",
        "  return np.array(input_ids_all), np.array(input_mask_all), np.array(segment_ids_all)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9qLcI6X9ftl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(input_text):\n",
        "  input_ids, input_mask, segment_ids = create_input(\n",
        "    input_text, tokenizer, MAX_SEQ_LENGTH)\n",
        "  return labse_model([input_ids, input_mask, segment_ids])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btvoUe1h9p2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng_sentence = [\"Thanks, I like this chair\", \"I didn't like it\"]\n",
        "hi_sentence = [\"धन्यवाद, मुझे यह कुर्सी पसंद है\", \"मुझे यह पसंद नहीं आया\"]\n",
        "hinglish_sentence = [\"dhanyawaad, mujhe yeh kursi pasand hai\", \"Mujhe yeh pasand nahi aayi\"]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ulnzmp28-CmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_embeddings = encode(eng_sentence)\n",
        "hi_embeddings = encode(hi_sentence)\n",
        "hinglish_embeddings = encode(hinglish_sentence)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0a5sFZW_JSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "064e2d38-d25c-451e-c774-91958bb603a6"
      },
      "source": [
        "en_embeddings.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwWQiY8N-4iX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "53011488-e162-49cd-a729-cc087686403d"
      },
      "source": [
        "# English-Hindi similarity\n",
        "print (np.matmul(en_embeddings, np.transpose(hi_embeddings)))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9189365  0.39174503]\n",
            " [0.4012831  0.9497982 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EbAzLmq-4e9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b1932bdf-81c6-467e-d7c6-542544d99596"
      },
      "source": [
        "# English-Hinglish Similarity\n",
        "print (np.matmul(en_embeddings, np.transpose(hinglish_embeddings)))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.40627664 0.12593725]\n",
            " [0.03425898 0.16832921]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkXFn43wA6ei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "4d69960d-78f3-4c61-b357-c0089eb79bc1"
      },
      "source": [
        "english_sentences = [\"dog\", \"Puppies are nice.\", \"I enjoy taking long walks along the beach with my dog.\"]\n",
        "italian_sentences = [\"cane\", \"I cuccioli sono carini.\", \"Mi piace fare lunghe passeggiate lungo la spiaggia con il mio cane.\"]\n",
        "japanese_sentences = [\"犬\", \"子犬はいいです\", \"私は犬と一緒にビーチを散歩するのが好きです\"]\n",
        "\n",
        "\n",
        "english_embeddings = encode(english_sentences)\n",
        "italian_embeddings = encode(italian_sentences)\n",
        "japanese_embeddings = encode(japanese_sentences)\n",
        "\n",
        "# English-Italian similarity\n",
        "print (np.matmul(english_embeddings, np.transpose(italian_embeddings)))\n",
        "\n",
        "# English-Japanese similarity\n",
        "print (np.matmul(english_embeddings, np.transpose(japanese_embeddings)))\n",
        "\n",
        "# Italian-Japanese similarity\n",
        "print (np.matmul(italian_embeddings, np.transpose(japanese_embeddings)))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.63192904 0.3061977  0.44297487]\n",
            " [0.11652687 0.8596667  0.35940546]\n",
            " [0.1480399  0.32447964 0.95426506]]\n",
            "[[0.93567216 0.54030645 0.46792305]\n",
            " [0.31804204 0.7622249  0.3608588 ]\n",
            " [0.36750704 0.42791563 0.81714547]]\n",
            "[[0.5343719  0.25018615 0.19974725]\n",
            " [0.30140817 0.71333206 0.4064753 ]\n",
            " [0.3850308  0.47767898 0.86742973]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KuotKwPTtuR",
        "colab_type": "text"
      },
      "source": [
        "#### References\n",
        "\n",
        "1. https://tfhub.dev/google/LaBSE/1\n",
        "2. [Language agnostic BERT Sentence Embedding](https://arxiv.org/pdf/2007.01852.pdf)"
      ]
    }
  ]
}